# AI Model Performance Analysis - Presentation Ready

**Generated:** 2025-07-22  
**Total Models Tested:** 25  
**Overall Success Rate:** 100%  
**Test Query:** "What is 2+2?" (50 tokens max)

## ðŸš€ Complete Model Speed Rankings

| Rank | Provider | Model | Speed | Daily Limits | Context | Notes |
|------|----------|-------|-------|--------------|---------|-------|
| 1 | **Cerebras** | Llama 3.3 70B | **0.29s** | 30 req/min | 131K tokens | Ultra-fast, enterprise-grade |
| 2 | **Groq** | Llama 4 Scout 17B | **0.35s** | 30 req/min | 131K tokens | Latest Llama 4, production-ready |
| 3 | **Groq** | Llama 3.3 70B Versatile | **0.35s** | 30 req/min | 131K tokens | Large model, versatile |
| 4 | **Cerebras** | Llama 4 Scout 17B | **0.38s** | 30 req/min | 131K tokens | Fastest Llama 4 variant |
| 5 | **Cerebras** | Llama 3.1 8B | **0.42s** | 30 req/min | 8K tokens | Lightweight, efficient |
| 6 | **Groq** | Llama 3.1 8B Instant | **0.44s** | 30 req/min | 131K tokens | Instant responses |
| 7 | **Groq** | Llama 4 Maverick 17B | **0.44s** | 30 req/min | 131K tokens | Advanced reasoning |
| 8 | **Groq** | Qwen 3 32B | **0.45s** | 30 req/min | 131K tokens | Multilingual excellence |
| 9 | **Cerebras** | Qwen 3 32B | **0.55s** | 30 req/min | 131K tokens | Alternative architecture |
| 10 | **Cloudflare** | Llama 3.1 70B | **0.79s** | 1000 req/day | 128K tokens | Serverless, global edge |
| 11 | **OpenRouter** | DeepHermes 3 8B | **0.81s** | 200 req/day | 131K tokens | Nous Research quality |
| 12 | **Cloudflare** | Llama 3.3 70B FP8 | **0.95s** | 1000 req/day | 128K tokens | FP8 optimized |
| 13 | **OpenRouter** | Kimi VL A3B Thinking | **1.00s** | 200 req/day | 131K tokens | Vision + thinking model |
| 14 | **Cloudflare** | Llama 4 Scout 17B | **1.33s** | 1000 req/day | 16K tokens | Latest Llama 4 |
| 15 | **OpenRouter** | Google Gemma 3 27B | **1.56s** | 200 req/day | 96K tokens | Google flagship |
| 16 | **OpenRouter** | Llama 3.2 11B Vision | **1.80s** | 200 req/day | 131K tokens | Vision capabilities |
| 17 | **OpenRouter** | MoonshotAI Kimi K2 | **2.04s** | 200 req/day | 65K tokens | Alternative architecture |
| 18 | **OpenRouter** | Google Gemma 3 12B | **2.05s** | 200 req/day | 96K tokens | Balanced performance |
| 19 | **OpenRouter** | DeepSeek R1T Chimera | **2.14s** | 200 req/day | 163K tokens | R1 reasoning style |
| 20 | **OpenRouter** | Mistral Small 3.2 24B | **2.18s** | 200 req/day | 96K tokens | Latest Mistral |
| 21 | **Cloudflare** | DeepSeek R1 Qwen 32B | **2.54s** | 1000 req/day | 32K tokens | Advanced reasoning |
| 22 | **OpenRouter** | Qwen 3 235B A22B | **2.68s** | 200 req/day | 131K tokens | Massive 235B model |
| 23 | **OpenRouter** | Mistral Small 3.1 24B | **2.76s** | 200 req/day | 128K tokens | Proven reliability |
| 24 | **OpenRouter** | Mistral Nemo | **3.14s** | 200 req/day | 131K tokens | Mistral architecture |
| 25 | **Cloudflare** | Qwen QwQ 32B | **8.85s** | 1000 req/day | 32K tokens | Question-answering optimized |

## ðŸ“Š Provider Summary

### **Cerebras (4 models)**
- **Speed Range:** 0.29s - 0.55s
- **Daily Limits:** 30 requests/minute
- **Strengths:** Fastest overall, consistent performance
- **Best For:** Speed-critical applications

### **Groq (5 models)**  
- **Speed Range:** 0.35s - 0.45s
- **Daily Limits:** 30 requests/minute
- **Strengths:** Excellent speed-reliability balance
- **Best For:** Production workloads

### **Cloudflare (5 models)**
- **Speed Range:** 0.79s - 8.85s  
- **Daily Limits:** 1000 requests/day
- **Strengths:** Serverless, global edge deployment
- **Best For:** High-volume applications

### **OpenRouter (11 models)**
- **Speed Range:** 0.81s - 3.14s
- **Daily Limits:** 200 requests/day (free tier)
- **Strengths:** Model diversity, specialized capabilities
- **Best For:** Research, experimentation

## ðŸŽ¯ Key Insights for Presentation

1. **Ultra-Fast Tier (< 0.5s):** 9 models from Cerebras & Groq
2. **Fast Tier (0.5s - 1.5s):** 4 models from Cloudflare & OpenRouter  
3. **Standard Tier (1.5s - 3.5s):** 11 models from OpenRouter
4. **Specialized Tier (> 3.5s):** 1 model (QwQ for complex reasoning)

## ðŸ’¡ Recommendations

- **For Speed:** Cerebras Llama 3.3 70B (0.29s)
- **For Balance:** Groq Llama 4 Scout 17B (0.35s)
- **For Volume:** Cloudflare Llama 3.1 70B (0.79s, 1000/day)
- **For Diversity:** OpenRouter models (11 options, various architectures)
