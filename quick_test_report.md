# Fallback LLM System - Model & Provider Performance Report

**Generated:** 2025-07-22 11:17:39

## Executive Summary

- **Total Models Tested:** 13
- **Total Requests:** 13
- **Overall Success Rate:** 92.3%
- **Providers Available:** 3

## Provider Performance Analysis

### Cerebras Provider

**Provider Summary:**
- Models Available: 4
- Total Requests: 4
- Success Rate: 100.0%
- Average Response Time: 0.32s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `qwen-3-32b` | 1 | 100.0% | 0.26s | 0.26s | 0.26s | 2025-07-22 11:17:24 |
| `llama-4-scout-17b-16e-instruct` | 1 | 100.0% | 0.28s | 0.28s | 0.28s | 2025-07-22 11:17:21 |
| `llama3.1-8b` | 1 | 100.0% | 0.30s | 0.30s | 0.30s | 2025-07-22 11:17:23 |
| `llama-3.3-70b` | 1 | 100.0% | 0.46s | 0.46s | 0.46s | 2025-07-22 11:17:22 |

### Groq Provider

**Provider Summary:**
- Models Available: 5
- Total Requests: 5
- Success Rate: 100.0%
- Average Response Time: 0.49s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `meta-llama/llama-4-scout-17b-16e-instruct` | 1 | 100.0% | 0.39s | 0.39s | 0.39s | 2025-07-22 11:17:26 |
| `llama-3.1-8b-instant` | 1 | 100.0% | 0.43s | 0.43s | 0.43s | 2025-07-22 11:17:28 |
| `llama-3.3-70b-versatile` | 1 | 100.0% | 0.50s | 0.50s | 0.50s | 2025-07-22 11:17:29 |
| `qwen/qwen3-32b` | 1 | 100.0% | 0.54s | 0.54s | 0.54s | 2025-07-22 11:17:27 |
| `meta-llama/llama-4-maverick-17b-128e-instruct` | 1 | 100.0% | 0.59s | 0.59s | 0.59s | 2025-07-22 11:17:25 |

### Openrouter Provider

**Provider Summary:**
- Models Available: 4
- Total Requests: 4
- Success Rate: 75.0%
- Average Response Time: 1.99s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `mistralai/mistral-small-3.1-24b-instruct:free` | 1 | 100.0% | 1.86s | 1.86s | 1.86s | 2025-07-22 11:17:38 |
| `mistralai/mistral-nemo:free` | 1 | 100.0% | 1.97s | 1.97s | 1.97s | 2025-07-22 11:17:31 |
| `tngtech/deepseek-r1t-chimera:free` | 1 | 100.0% | 2.15s | 2.15s | 2.15s | 2025-07-22 11:17:34 |
| `google/gemini-2.0-flash-exp:free` | 1 | 0.0% | N/A | N/A | N/A | 2025-07-22 11:17:36 |

## Performance Rankings

### ðŸš€ Fastest Models (by average response time)

| Rank | Provider | Model | Avg Response Time | Success Rate |
|------|----------|-------|-------------------|--------------|
| 1 | Cerebras | `qwen-3-32b` | 0.26s | 100.0% |
| 2 | Cerebras | `llama-4-scout-17b-16e-instruct` | 0.28s | 100.0% |
| 3 | Cerebras | `llama3.1-8b` | 0.30s | 100.0% |
| 4 | Groq | `meta-llama/llama-4-scout-17b-16e-instruct` | 0.39s | 100.0% |
| 5 | Groq | `llama-3.1-8b-instant` | 0.43s | 100.0% |
| 6 | Cerebras | `llama-3.3-70b` | 0.46s | 100.0% |
| 7 | Groq | `llama-3.3-70b-versatile` | 0.50s | 100.0% |
| 8 | Groq | `qwen/qwen3-32b` | 0.54s | 100.0% |
| 9 | Groq | `meta-llama/llama-4-maverick-17b-128e-instruct` | 0.59s | 100.0% |
| 10 | Openrouter | `mistralai/mistral-small-3.1-24b-instruct:free` | 1.86s | 100.0% |

### ðŸŽ¯ Most Reliable Models (by success rate)

| Rank | Provider | Model | Success Rate | Avg Response Time |
|------|----------|-------|--------------|-------------------|
| 1 | Cerebras | `qwen-3-32b` | 100.0% | 0.26s |
| 2 | Cerebras | `llama-4-scout-17b-16e-instruct` | 100.0% | 0.28s |
| 3 | Cerebras | `llama3.1-8b` | 100.0% | 0.30s |
| 4 | Groq | `meta-llama/llama-4-scout-17b-16e-instruct` | 100.0% | 0.39s |
| 5 | Groq | `llama-3.1-8b-instant` | 100.0% | 0.43s |
| 6 | Cerebras | `llama-3.3-70b` | 100.0% | 0.46s |
| 7 | Groq | `llama-3.3-70b-versatile` | 100.0% | 0.50s |
| 8 | Groq | `qwen/qwen3-32b` | 100.0% | 0.54s |
| 9 | Groq | `meta-llama/llama-4-maverick-17b-128e-instruct` | 100.0% | 0.59s |
| 10 | Openrouter | `mistralai/mistral-small-3.1-24b-instruct:free` | 100.0% | 1.86s |

## Recommendations

- **For Speed:** Use `cerebras` with model `qwen-3-32b` (avg: 0.26s)
- **For Reliability:** Use `cerebras` with model `llama-4-scout-17b-16e-instruct` (success rate: 100.0%)
- **Best Overall:** Use `cerebras` with model `qwen-3-32b` (balanced performance)

---
*Report generated by Fallback LLM System*