# Fallback LLM System - Model & Provider Performance Report

**Generated:** 2025-07-22 11:16:55

## Executive Summary

- **Total Models Tested:** 13
- **Total Requests:** 13
- **Overall Success Rate:** 92.3%
- **Providers Available:** 3

## Provider Performance Analysis

### Cerebras Provider

**Provider Summary:**
- Models Available: 4
- Total Requests: 4
- Success Rate: 100.0%
- Average Response Time: 0.38s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `llama-3.3-70b` | 1 | 100.0% | 0.34s | 0.34s | 0.34s | 2025-07-22 11:16:30 |
| `qwen-3-32b` | 1 | 100.0% | 0.37s | 0.37s | 0.37s | 2025-07-22 11:16:32 |
| `llama3.1-8b` | 1 | 100.0% | 0.40s | 0.40s | 0.40s | 2025-07-22 11:16:31 |
| `llama-4-scout-17b-16e-instruct` | 1 | 100.0% | 0.43s | 0.43s | 0.43s | 2025-07-22 11:16:29 |

### Groq Provider

**Provider Summary:**
- Models Available: 5
- Total Requests: 5
- Success Rate: 100.0%
- Average Response Time: 0.36s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `meta-llama/llama-4-scout-17b-16e-instruct` | 1 | 100.0% | 0.33s | 0.33s | 0.33s | 2025-07-22 11:16:33 |
| `llama-3.3-70b-versatile` | 1 | 100.0% | 0.33s | 0.33s | 0.33s | 2025-07-22 11:16:36 |
| `llama-3.1-8b-instant` | 1 | 100.0% | 0.34s | 0.34s | 0.34s | 2025-07-22 11:16:35 |
| `meta-llama/llama-4-maverick-17b-128e-instruct` | 1 | 100.0% | 0.39s | 0.39s | 0.39s | 2025-07-22 11:16:33 |
| `qwen/qwen3-32b` | 1 | 100.0% | 0.40s | 0.40s | 0.40s | 2025-07-22 11:16:34 |

### Openrouter Provider

**Provider Summary:**
- Models Available: 4
- Total Requests: 4
- Success Rate: 75.0%
- Average Response Time: 4.36s

| Model | Requests | Success Rate | Avg Response Time | Min Time | Max Time | Last Tested |
|-------|----------|--------------|-------------------|----------|----------|-------------|
| `mistralai/mistral-small-3.1-24b-instruct:free` | 1 | 100.0% | 3.99s | 3.99s | 3.99s | 2025-07-22 11:16:55 |
| `tngtech/deepseek-r1t-chimera:free` | 1 | 100.0% | 4.44s | 4.44s | 4.44s | 2025-07-22 11:16:46 |
| `mistralai/mistral-nemo:free` | 1 | 100.0% | 4.65s | 4.65s | 4.65s | 2025-07-22 11:16:41 |
| `google/gemini-2.0-flash-exp:free` | 1 | 0.0% | N/A | N/A | N/A | 2025-07-22 11:16:50 |

## Performance Rankings

### ðŸš€ Fastest Models (by average response time)

| Rank | Provider | Model | Avg Response Time | Success Rate |
|------|----------|-------|-------------------|--------------|
| 1 | Groq | `meta-llama/llama-4-scout-17b-16e-instruct` | 0.33s | 100.0% |
| 2 | Groq | `llama-3.3-70b-versatile` | 0.33s | 100.0% |
| 3 | Cerebras | `llama-3.3-70b` | 0.34s | 100.0% |
| 4 | Groq | `llama-3.1-8b-instant` | 0.34s | 100.0% |
| 5 | Cerebras | `qwen-3-32b` | 0.37s | 100.0% |
| 6 | Groq | `meta-llama/llama-4-maverick-17b-128e-instruct` | 0.39s | 100.0% |
| 7 | Cerebras | `llama3.1-8b` | 0.40s | 100.0% |
| 8 | Groq | `qwen/qwen3-32b` | 0.40s | 100.0% |
| 9 | Cerebras | `llama-4-scout-17b-16e-instruct` | 0.43s | 100.0% |
| 10 | Openrouter | `mistralai/mistral-small-3.1-24b-instruct:free` | 3.99s | 100.0% |

### ðŸŽ¯ Most Reliable Models (by success rate)

| Rank | Provider | Model | Success Rate | Avg Response Time |
|------|----------|-------|--------------|-------------------|
| 1 | Groq | `meta-llama/llama-4-scout-17b-16e-instruct` | 100.0% | 0.33s |
| 2 | Groq | `llama-3.3-70b-versatile` | 100.0% | 0.33s |
| 3 | Cerebras | `llama-3.3-70b` | 100.0% | 0.34s |
| 4 | Groq | `llama-3.1-8b-instant` | 100.0% | 0.34s |
| 5 | Cerebras | `qwen-3-32b` | 100.0% | 0.37s |
| 6 | Groq | `meta-llama/llama-4-maverick-17b-128e-instruct` | 100.0% | 0.39s |
| 7 | Cerebras | `llama3.1-8b` | 100.0% | 0.40s |
| 8 | Groq | `qwen/qwen3-32b` | 100.0% | 0.40s |
| 9 | Cerebras | `llama-4-scout-17b-16e-instruct` | 100.0% | 0.43s |
| 10 | Openrouter | `mistralai/mistral-small-3.1-24b-instruct:free` | 100.0% | 3.99s |

## Recommendations

- **For Speed:** Use `groq` with model `meta-llama/llama-4-scout-17b-16e-instruct` (avg: 0.33s)
- **For Reliability:** Use `cerebras` with model `llama-4-scout-17b-16e-instruct` (success rate: 100.0%)
- **Best Overall:** Use `groq` with model `meta-llama/llama-4-scout-17b-16e-instruct` (balanced performance)

---
*Report generated by Fallback LLM System*